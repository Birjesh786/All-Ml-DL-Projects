{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPmzOG93XjLNgxJ14bNOe8R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Birjesh786/All-Ml-DL-Projects/blob/main/Normalization_Layers_to_Improve_Deep_Learning_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalization Layers to Improve Deep Learning Models"
      ],
      "metadata": {
        "id": "mJOByjTBfAYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Normalization layers play a crucial role in enhancing the training and performance of deep learning models. These layers are specifically designed to address issues related to internal covariate shift, which occurs when the distribution of the input to a particular layer changes during training. The concept of normalization in deep learning gained prominence with the introduction of techniques such as Batch Normalization (BN) and Layer Normalization (LN)."
      ],
      "metadata": {
        "id": "YU0cweirfynz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample presention of normalization"
      ],
      "metadata": {
        "id": "0ijzRcznfJh5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFTiZppuM0ph"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Activation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a simple example dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to be between 0 and 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAdK58xzSDjM",
        "outputId": "5a5a83dd-ec0d-4e65-afac-f5f13010d2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a simple neural network with Batch Normalization\n",
        "model = Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # Flatten the input images\n",
        "    Dense(128),\n",
        "    BatchNormalization(),  # Add Batch Normalization layer\n",
        "    Activation('relu'),   # Add ReLU activation function\n",
        "    Dense(10, activation='softmax')  # Output layer with softmax activation for classification\n",
        "])"
      ],
      "metadata": {
        "id": "2u51hc1TTiby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "UtyBiqx4TnOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2shS80MyTqaA",
        "outputId": "0685eb6f-7495-4950-d271-a441b3947888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 13s 4ms/step - loss: 0.2511 - accuracy: 0.9273 - val_loss: 0.1277 - val_accuracy: 0.9648\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1226 - accuracy: 0.9643 - val_loss: 0.0959 - val_accuracy: 0.9711\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0905 - accuracy: 0.9725 - val_loss: 0.0848 - val_accuracy: 0.9748\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0730 - accuracy: 0.9775 - val_loss: 0.0732 - val_accuracy: 0.9771\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0618 - accuracy: 0.9811 - val_loss: 0.0812 - val_accuracy: 0.9760\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7930bee8e440>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a_xOhjXTs9D",
        "outputId": "9717cc3c-1c7c-4b4f-9731-5138cf47160e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0812 - accuracy: 0.9760\n",
            "Test accuracy: 0.9760000109672546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply normalization CIFAR-100 data"
      ],
      "metadata": {
        "id": "uwKZNyL9fSVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar100"
      ],
      "metadata": {
        "id": "5xBiHjJ9T7jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMG-pFILVYb3",
        "outputId": "9d4e46a3-211d-445a-a3b1-617586f8a9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "mnjW2yqTVyf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a CNN with Batch Normalization\n",
        "model = models.Sequential()"
      ],
      "metadata": {
        "id": "Hc5RhddAV3MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional layers with Batch Normalization and ReLU activation\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())"
      ],
      "metadata": {
        "id": "qQKGZE_sV5gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fully connected layers with Batch Normalization and ReLU activation\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(100, activation='softmax'))  # Output layer with 100 classes"
      ],
      "metadata": {
        "id": "yP-beZmOV9un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "EwGm4pbCWAUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoLRfjAIWC-X",
        "outputId": "0a2c7e1e-95ab-44f4-f1b7-a5d12aa3c7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1824 - accuracy: 0.9416 - val_loss: 3.7691 - val_accuracy: 0.4185\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1564 - accuracy: 0.9487 - val_loss: 4.0125 - val_accuracy: 0.4004\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1542 - accuracy: 0.9505 - val_loss: 4.1138 - val_accuracy: 0.4212\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1371 - accuracy: 0.9553 - val_loss: 4.1773 - val_accuracy: 0.4165\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1271 - accuracy: 0.9589 - val_loss: 4.3467 - val_accuracy: 0.4101\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1229 - accuracy: 0.9603 - val_loss: 4.3414 - val_accuracy: 0.4174\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1159 - accuracy: 0.9617 - val_loss: 4.5058 - val_accuracy: 0.4271\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1174 - accuracy: 0.9619 - val_loss: 4.5932 - val_accuracy: 0.4243\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1014 - accuracy: 0.9669 - val_loss: 4.5873 - val_accuracy: 0.4096\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1004 - accuracy: 0.9669 - val_loss: 4.7574 - val_accuracy: 0.4129\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79309c033370>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGvAN4ApWFRQ",
        "outputId": "20b74abc-e785-4f1e-8ba0-694ea4fad27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 4.7574 - accuracy: 0.4129\n",
            "Test accuracy: 0.41290000081062317\n"
          ]
        }
      ]
    }
  ]
}